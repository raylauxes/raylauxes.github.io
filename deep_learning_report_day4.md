# 深層学習day4レポート(強化学習)

![Image](/bnr_jdla.png)
http://study-ai.com/jdla/


### DL04-001_強化学習1
![Image](/DL04-001_強化学習1_00m40s.png)
```
強化学習とは、長期的に報酬を最大化できるように環境のなかで行動を選択できるエージェントを作ることを目標とする機械学習の一分野
```
![Image](/DL04-001_強化学習1_06m30s.png)


### DL04-002_強化学習2
```
強化学習の応用例：
誰にキャンペーンのメールを送ろうか？
激安品しか買わない顧客に送ると、損になる。キャンペーン商品とほかの商品を一緒に買ってくれそうなお客に送ると売り上げが上がる！
```


### DL04-003_強化学習3
```
「教師あり・なし学習」と「強化学習」の違い：目標が違う！

教師あり・なし学習では、データに含まれるパターン（特徴！）を見つけ出すおよびそのデータから予測することが目標

強化学習では、優れた方策を見つけることが目標
```
```
Q学習：行動価値関数を、行動する毎に更新することにより学習を進める方法

関数近似法：価値関数や方策関数を関数近似する手法のこと
```


### DL04-004_強化学習4
```
価値関数は２種ある：
1、状態価値関数
2、行動価値関数
```
```
方策関数（ほうさくかんすう）とは、エージェントが状況によるどう反応するかを決める関数。
価値関数を最大値を出すように、方策関数が動いている
```
![Image](/.png)



### 
```

```
![Image](/.png)
> 実演リンク：[title](https://)


### 
```

```
![Image](/.png)
> 実演リンク：[title](https://)


### 
```

```
![Image](/.png)
> 実演リンク：[title](https://)


### 
```

```
![Image](/.png)
> 実演リンク：[title](https://)





例例例例例例例例例例例例例例例例例例例例例例例例例例例例例例例例例例例例例例例例例
#### 00:02:00- CNNの構造図復習


#### 00:05:00- AlexNetのモデルの説明
![Image](/深層学習day3-1_00h07m30s.png)


#### 00:14:15- 再帰型ニューラルネットワーク
```
RNNとは、時系列データ（例：音声データ、テキストデータ、株価）に対応できるニューラルネットワーク
```


#### 00:24:25- RNNの全体像
```
x：入力層
Z：中間層
y：出力層
```
![Image](/深層学習day3-1_00h25m00s.png)
> 「unfold」の右には、左の詳細説明

> 修正：Z -> y


##### 00:33:00- RNNの全体像(2)
![Image](/深層学習day3-1_00h41m25s.png)


##### 00:36:15- RNNの数学的記述
![Image](/深層学習day3-1_00h37m11s.png)
![Image](/深層学習day3-1_00h40m30s.png)


##### 00:43:30- 確認テスト 
```
RNNのネットワークには大きく分けて3つの重みがある：
1、W(in)：入力から現在の中間層を定義する際にかけられる重み
2、W（out）：中間層から出力を定義する際にかけられる重み
3、W：前の中間層から中間層の重み
```


##### 00:48:10- RNNの特徴
```
時系列モデルを扱うには、初期の状態と過去の時間t-1の状態を保持し、そこから次の時間でのtを再帰的に求める再帰構造が必要になる。
```


##### 00:50:00- simple RNN
```
simple RNNでバイナリ加算をやってみよう！
```
> 実演リンク：[3_1_simple_RNN.ipynb](https://drive.google.com/file/d/1wt-wGSfbi21PVI6ilKXwsNYW95Qg1yiH/view?usp=sharing)


##### 00:59:10- 演習チャレンジ
![Image](/深層学習day3-1_00h59m00s.png)


##### 00:59:10-01:08:00 構文木（こうぶんぎ）
```
10個+10個 -> 20個 -> 10個
```
![Image](/深層学習day3-1_01h08m07s.png)



### 01:18:00- 1-2 BPTT
#### 01:18:00- 1-2-1 BPTTとは
```
BPTTとは、RNNにおいてのパラメータ調整方法の一種（誤差逆伝播の一種）
```
> BPTT：back propogation through time?


#### 01:19:30- 誤差逆伝播法の復習
![Image](/深層学習day3-1_01h20m53s.png)
![Image](/深層学習day3-1_01h22m00s.png)


#####
> 実演リンク：[3_1_simple_RNN.ipynb](https://drive.google.com/file/d/1wt-wGSfbi21PVI6ilKXwsNYW95Qg1yiH/view?usp=sharing)


#### 01:39:00-  1-2-2 BPTTの数学的記述
```
BPTTの数学的記述
```
![Image](/深層学習day3-1_01h39m50s.png)

```
数式とコード
```
![Image](/深層学習day3-1_01h41m50s.png)
![Image](/深層学習day3-1_01h52m00s.png)
![Image](/深層学習day3-1_01h56m00s.png)
![Image](/深層学習day3-1_01h56m30s.png)


##### 01:58:00- 確認テスト
![Image](/深層学習day3-1_02h08m30s.png)


##### 02:08:50- BPTTの数学的記述3
```

```
![Image](/.png)
> 実演リンク：[title](https://)

##### 02:00:00-
```

```
![Image](/.png)
> 実演リンク：[title](https://)


##### 02:00:00-
```

```
![Image](/.png)
> 実演リンク：[title](https://)

##### 02:00:00-
```

```
![Image](/.png)
> 実演リンク：[title](https://)
